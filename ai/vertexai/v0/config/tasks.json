{
  "$defs": {
    "multi-modal-content": {
      "instillFormat": "structured/multi-modal-content",
      "items": {
        "properties": {
          "image-url": {
            "properties": {
              "url": {
                "description": "Either a URL of the image or the base64 encoded image data.",
                "type": "string"
              }
            },
            "required": [
              "url"
            ],
            "type": "object"
          },
          "text": {
            "description": "The text content.",
            "instillFormat": "string",
            "type": "string"
          },
          "type": {
            "description": "The type of the content part.",
            "enum": [
              "text",
              "image_url"
            ],
            "instillFormat": "string",
            "type": "string"
          }
        },
        "required": [
          "type"
        ],
        "type": "object"
      },
      "type": "array"
    },
    "chat-message": {
      "properties": {
        "content": {
          "$ref": "#/$defs/multi-modal-content",
          "description": "The message content",
          "instillUIOrder": 1,
          "title": "Content"
        },
        "role": {
          "description": "The message role, i.e. 'system', 'user' or 'assistant'",
          "instillFormat": "string",
          "instillUIOrder": 0,
          "title": "Role",
          "type": "string"
        }
      },
      "required": [
        "role",
        "content"
      ],
      "title": "Chat Message",
      "type": "object"
    },
    "usage": {
      "description": "Token usage on Vertex AI platform",
      "instillUIOrder": 1,
      "properties": {
        "input-tokens": {
          "description": "The input tokens used by Vertex AI models",
          "instillFormat": "number",
          "instillUIOrder": 2,
          "title": "Input Tokens",
          "type": "number"
        },
        "output-tokens": {
          "description": "The output tokens generated by Vertex AI models",
          "instillFormat": "number",
          "instillUIOrder": 3,
          "title": "Output Tokens",
          "type": "number"
        }
      },
      "required": [
        "input-tokens",
        "output-tokens"
      ],
      "title": "Usage",
      "type": "object"
    }
  },
  "TASK_TEXT_GENERATION_CHAT": {
    "instillShortDescription": "Provide text outputs in response to text inputs.",
    "description": "Google's text generation models (often called generative pre-trained transformers or large language models) have been trained to understand natural language, code, and images. The models provide text outputs in response to their inputs. The inputs to these models are also referred to as \"prompts\". Designing a prompt is essentially how you \u201cprogram\u201d a large language model model, usually by providing instructions or some examples of how to successfully complete a task.",
    "input": {
      "description": "Input",
      "instillEditOnNodeFields": [
        "prompt",
        "model-name"
      ],
      "instillUIOrder": 0,
      "properties": {
        "chat-history": {
          "description": "Incorporate external chat history, specifically previous messages within the conversation. Please note that System Message will be ignored and will not have any effect when this field is populated. Each message should adhere to the format: : {\"role\": \"The message role, i.e. 'system', 'user' or 'assistant'\", \"content\": \"message content\"}.",
          "instillAcceptFormats": [
            "structured/chat-messages"
          ],
          "instillShortDescription": "Incorporate external chat history, specifically previous messages within the conversation. The Gemini family of models supports diverse input data types, including text, images, videos and audio. The model can generate text, images, videos and audio.",
          "instillUIOrder": 4,
          "instillUpstreamTypes": [
            "reference"
          ],
          "items": {
            "$ref": "#/$defs/chat-message"
          },
          "title": "Chat history",
          "type": "array"
        },
        "max-new-tokens": {
          "default": 50,
          "description": "The maximum number of tokens for model to generate",
          "instillAcceptFormats": [
            "integer"
          ],
          "instillUIOrder": 6,
          "instillUpstreamTypes": [
            "value",
            "reference"
          ],
          "title": "Max new tokens",
          "type": "integer"
        },
        "model-name": {
          "enum": [
            "gemini-1.5-pro",
            "gemini-1.5-flash",
            "gemini-1.0-pro",
            "gemma-7b-it"
          ],
          "example": "gemini-1.5-pro",
          "description": "The Vertex Generative AI model to be used.",
          "instillAcceptFormats": [
            "string"
          ],
          "instillUIOrder": 0,
          "instillUpstreamTypes": [
            "value",
            "reference",
            "template"
          ],
          "title": "Model Name",
          "type": "string"
        },
        "prompt": {
          "description": "The prompt text",
          "instillAcceptFormats": [
            "string"
          ],
          "instillUIMultiline": true,
          "instillUIOrder": 2,
          "instillUpstreamTypes": [
            "value",
            "reference",
            "template"
          ],
          "title": "Prompt",
          "type": "string"
        },
        "prompt-images": {
          "description": "The prompt images",
          "instillAcceptFormats": [
            "array:image/*"
          ],
          "instillUIOrder": 3,
          "instillUpstreamTypes": [
            "reference"
          ],
          "items": {
            "type": "string"
          },
          "title": "Prompt Images",
          "type": "array"
        },
        "seed": {
          "description": "The seed (Note: Not supported by Vertex Generative AI Models)",
          "instillAcceptFormats": [
            "integer"
          ],
          "instillUIOrder": 4,
          "instillUpstreamTypes": [
            "value",
            "reference"
          ],
          "title": "Seed",
          "type": "integer"
        },
        "system-message": {
          "default": "You are a helpful assistant.",
          "description": "The system message helps set the behavior of the assistant. For example, you can modify the personality of the assistant or provide specific instructions about how it should behave throughout the conversation. By default, the model\u2019s behavior is using a generic message as \"You are a helpful assistant.\"",
          "instillAcceptFormats": [
            "string"
          ],
          "instillShortDescription": "The system message helps set the behavior of the assistant",
          "instillUIMultiline": true,
          "instillUIOrder": 2,
          "instillUpstreamTypes": [
            "value",
            "reference",
            "template"
          ],
          "title": "System message",
          "type": "string"
        },
        "temperature": {
          "default": 0.7,
          "description": "The temperature for sampling",
          "instillAcceptFormats": [
            "number"
          ],
          "instillUIOrder": 5,
          "instillUpstreamTypes": [
            "value",
            "reference"
          ],
          "title": "Temperature",
          "type": "number"
        },
        "top-k": {
          "default": 10,
          "description": "Top k for sampling",
          "instillAcceptFormats": [
            "integer"
          ],
          "instillUIOrder": 5,
          "instillUpstreamTypes": [
            "value",
            "reference"
          ],
          "title": "Top K",
          "type": "integer"
        }
      },
      "required": [
        "prompt",
        "model-name"
      ],
      "title": "Input",
      "type": "object"
    },
    "output": {
      "description": "Output",
      "instillUIOrder": 0,
      "properties": {
        "text": {
          "description": "Model Output",
          "instillUIOrder": 0,
          "instillFormat": "string",
          "instillUIMultiline": true,
          "title": "Text",
          "type": "string"
        },
        "usage": {
          "$ref": "#/$defs/usage"
        }
      },
      "required": [
        "text"
      ],
      "title": "Output",
      "type": "object"
    }
  },
  "TASK_TEXT_TO_IMAGE": {
    "instillShortDescription": "Generate images from input text prompts.",
    "input": {
      "description": "Input",
      "instillEditOnNodeFields": [
        "prompt",
        "model-name"
      ],
      "instillUIOrder": 0,
      "properties": {
        "cfg-scale": {
          "description": "The guidance scale, default is 7.5",
          "instillAcceptFormats": [
            "number",
            "integer"
          ],
          "instillUIOrder": 4,
          "instillUpstreamTypes": [
            "value",
            "reference"
          ],
          "title": "CFG Scale",
          "type": "number"
        },
        "model-name": {
          "description": "The Vertex Generative AI Model model to be used.",
          "instillAcceptFormats": [
            "string"
          ],
          "enum": [
            "Imagen 2"
          ],
          "example": "Imagen 2",
          "instillUIOrder": 0,
          "instillUpstreamTypes": [
            "value",
            "reference",
            "template"
          ],
          "title": "Model Name",
          "type": "string"
        },
        "prompt": {
          "description": "The prompt text",
          "instillAcceptFormats": [
            "string"
          ],
          "instillUIMultiline": true,
          "instillUIOrder": 2,
          "instillUpstreamTypes": [
            "value",
            "reference",
            "template"
          ],
          "title": "Prompt",
          "type": "string"
        },
        "samples": {
          "description": "The number of generated samples, default is 1",
          "instillAcceptFormats": [
            "integer"
          ],
          "instillUIOrder": 5,
          "instillUpstreamTypes": [
            "value",
            "reference"
          ],
          "title": "Samples",
          "type": "integer"
        },
        "seed": {
          "description": "The seed, default is 0",
          "instillAcceptFormats": [
            "integer"
          ],
          "instillUIOrder": 6,
          "instillUpstreamTypes": [
            "value",
            "reference"
          ],
          "title": "Seed",
          "type": "integer"
        },
        "steps": {
          "description": "The steps, default is 5",
          "instillAcceptFormats": [
            "integer"
          ],
          "instillUIOrder": 7,
          "instillUpstreamTypes": [
            "value",
            "reference"
          ],
          "title": "Steps",
          "type": "integer"
        }
      },
      "required": [
        "prompt",
        "model-name"
      ],
      "title": "Input",
      "type": "object"
    },
    "output": {
      "description": "Output",
      "instillEditOnNodeFields": [
        "images"
      ],
      "instillUIOrder": 0,
      "properties": {
        "images": {
          "description": "Images",
          "instillUIOrder": 0,
          "instillFormat": "array:image/jpeg",
          "items": {
            "instillFormat": "image/jpeg",
            "title": "Image",
            "type": "string"
          },
          "title": "Images",
          "type": "array"
        }
      },
      "required": [
        "images"
      ],
      "title": "Output",
      "type": "object"
    }
  },
  "TASK_IMAGE_TO_IMAGE": {
    "instillShortDescription": "Generate image from input text prompt and image.",
    "input": {
      "description": "Input",
      "instillEditOnNodeFields": [
        "prompt",
        "image-base64",
        "model-name"
      ],
      "instillUIOrder": 0,
      "properties": {
        "cfg-scale": {
          "description": "The guidance scale, default is 7.5",
          "instillAcceptFormats": [
            "number",
            "integer"
          ],
          "instillUIOrder": 4,
          "instillUpstreamTypes": [
            "value",
            "reference"
          ],
          "title": "CFG Scale",
          "type": "number"
        },
        "model-name": {
          "description": "The Instill Model model to be used.",
          "instillAcceptFormats": [
            "string"
          ],
          "instillUIOrder": 0,
          "instillUpstreamTypes": [
            "value",
            "reference",
            "template"
          ],
          "title": "Model Name",
          "type": "string"
        },
        "prompt": {
          "description": "The prompt text",
          "instillAcceptFormats": [
            "string"
          ],
          "instillUIMultiline": true,
          "instillUIOrder": 2,
          "instillUpstreamTypes": [
            "value",
            "reference",
            "template"
          ],
          "title": "Prompt",
          "type": "string"
        },
        "samples": {
          "description": "The number of generated samples, default is 1",
          "instillAcceptFormats": [
            "integer"
          ],
          "instillUIOrder": 5,
          "instillUpstreamTypes": [
            "value",
            "reference"
          ],
          "title": "Samples",
          "type": "integer"
        },
        "seed": {
          "description": "The seed",
          "instillAcceptFormats": [
            "integer"
          ],
          "instillUIOrder": 4,
          "instillUpstreamTypes": [
            "value",
            "reference"
          ],
          "title": "Seed",
          "type": "integer"
        },
        "top-k": {
          "default": 10,
          "description": "Top k for sampling",
          "instillAcceptFormats": [
            "integer"
          ],
          "instillUIOrder": 5,
          "instillUpstreamTypes": [
            "value",
            "reference"
          ],
          "title": "Top K",
          "type": "integer"
        }
      },
      "required": [
        "prompt",
        "image-base64",
        "model-name"
      ],
      "title": "Input",
      "type": "object"
    },
    "output": {
      "description": "Output",
      "instillEditOnNodeFields": [
        "images"
      ],
      "instillUIOrder": 0,
      "properties": {
        "images": {
          "description": "Images",
          "instillUIOrder": 0,
          "instillFormat": "array:image/jpeg",
          "items": {
            "instillFormat": "image/jpeg",
            "title": "Image",
            "type": "string"
          },
          "title": "Images",
          "type": "array"
        }
      },
      "required": [
        "images"
      ],
      "title": "Output",
      "type": "object"
    }
  },
  "TASK_SPEECH_RECOGNITION": {
    "instillShortDescription": "Automatic Speech Recognition (ASR), also known as Speech to Text (STT), is the task of transcribing a given audio to text.",
    "description": "Automatic Speech Recognition (ASR), also known as Speech to Text (STT), is the task of transcribing a given audio to text. It has many applications, such as voice user interfaces.",
    "input": {
      "instillEditOnNodeFields": [
        "audio",
        "model-name",
        "language-code"
      ],
      "instillUIOrder": 0,
      "properties": {
        "audio": {
          "description": "The audio file",
          "instillAcceptFormats": [
            "audio/*"
          ],
          "instillUIOrder": 1,
          "instillUpstreamTypes": [
            "reference"
          ],
          "title": "Audio",
          "type": "string"
        },
        "model-name": {
          "description": "The Vertex Generative AI Model model to be used.",
          "instillAcceptFormats": [
            "string"
          ],
          "enum": [
            "Chirp"
          ],
          "example": "Chrip",
          "instillUIOrder": 0,
          "instillUpstreamTypes": [
            "value",
            "reference",
            "template"
          ],
          "title": "Model Name",
          "type": "string"
        },
        "sample-rate": {
          "description": "The sample rate of the audio file",
          "default": 16000,
          "instillAcceptFormats": [
            "integer"
          ],
          "instillUIOrder": 2,
          "instillUpstreamTypes": [
            "value",
            "reference"
          ],
          "title": "Sample Rate",
          "type": "integer"
        },
        "language-code": {
          "description": "The language code of the audio file, check: https://cloud.google.com/speech-to-text/docs/speech-to-text-supported-languages",
          "default": "en-US",
          "instillAcceptFormats": [
            "string"
          ],
          "instillUIOrder": 3,
          "instillUpstreamTypes": [
            "value",
            "reference"
          ],
          "title": "Language Code",
          "type": "string"
        }
      },
      "required": [
        "audio",
        "model-name",
        "language-code"
      ],
      "title": "Input",
      "type": "object"
    },
    "output": {
      "instillUIOrder": 0,
      "properties": {
        "text": {
          "description": "The string that was recognized within the audio file.",
          "instillFormat": "string",
          "instillUIMultiline": true,
          "instillUIOrder": 0,
          "title": "Text",
          "type": "string"
        }
      },
      "required": [
        "text"
      ],
      "title": "Output",
      "type": "object"
    }
  }
}
