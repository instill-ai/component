{
  "$defs": {
    "text": {
      "description": "Text to be chunked",
      "instillAcceptFormats": [
        "string"
      ],
      "instillUIMultiline": true,
      "instillUIOrder": 0,
      "instillUpstreamTypes": [
        "value",
        "reference",
        "template"
      ],
      "title": "Text",
      "type": "string"
    },
    "chunk_size": {
      "default": 512,
      "description": "An integer that sets the maximum number of characters allowed in a single chunk. This ensures that each chunk does not exceed a specified size.",
      "instillAcceptFormats": [
        "integer"
      ],
      "instillUIOrder": 0,
      "instillUpstreamTypes": [
        "value",
        "reference"
      ],
      "minimum": 1,
      "title": "Chunk Size",
      "type": "integer"
    },
    "chunk_overlap": {
      "default": 512,
      "description": "An integer that specifies the number of characters that should overlap between consecutive chunks. ",
      "instillAcceptFormats": [
        "integer"
      ],
      "instillUIOrder": 1,
      "instillUpstreamTypes": [
        "value",
        "reference"
      ],
      "minimum": 1,
      "title": "Chunk Size",
      "type": "integer"
    },
    "model_name": {
      "description": "ID of the model to use for tokenization",
      "enum": [
        "gpt-4",
        "gpt-3.5-turbo",
        "text-davinci-003",
        "text-davinci-002",
        "text-davinci-001",
        "text-curie-001",
        "text-babbage-001",
        "text-ada-001",
        "davinci",
        "curie",
        "babbage",
        "ada",
        "code-davinci-002",
        "code-davinci-001",
        "code-cushman-002",
        "code-cushman-001",
        "davinci-codex",
        "cushman-codex",
        "text-davinci-edit-001",
        "code-davinci-edit-001",
        "text-embedding-ada-002",
        "text-similarity-davinci-001",
        "text-similarity-curie-001",
        "text-similarity-babbage-001",
        "text-similarity-ada-001",
        "text-search-davinci-doc-001",
        "text-search-curie-doc-001",
        "text-search-babbage-doc-001",
        "text-search-ada-doc-001",
        "code-search-babbage-code-001",
        "code-search-ada-code-001",
        "gpt2"
      ],
      "instillAcceptFormats": [
        "string"
      ],
      "instillUIOrder": 2,
      "instillUpstreamTypes": [
        "value",
        "reference",
        "template"
      ],
      "title": "Model",
      "type": "string"
    }
  },
  "TASK_CONVERT_TO_TEXT": {
    "instillShortDescription": "Convert document to text.",
    "input": {
      "description": "Input",
      "instillEditOnNodeFields": [
        "doc"
      ],
      "instillUIOrder": 0,
      "properties": {
        "doc": {
          "description": "Base64 encoded document (PDF, DOC, DOCX, XML, HTML, RTF, etc.) to be converted to plain text",
          "instillAcceptFormats": [
            "*/*"
          ],
          "instillUIMultiline": true,
          "instillUIOrder": 0,
          "instillUpstreamTypes": [
            "reference"
          ],
          "title": "Document",
          "type": "string"
        }
      },
      "required": [
        "doc"
      ],
      "title": "Input",
      "type": "object"
    },
    "output": {
      "description": "Output",
      "instillUIOrder": 0,
      "properties": {
        "body": {
          "description": "Plain text converted from the document",
          "instillFormat": "string",
          "instillUIMultiline": true,
          "instillUIOrder": 0,
          "title": "Body",
          "type": "string"
        },
        "error": {
          "description": "Error message if any during the conversion process",
          "instillFormat": "string",
          "instillUIMultiline": true,
          "instillUIOrder": 3,
          "title": "Error",
          "type": "string"
        },
        "meta": {
          "description": "Metadata extracted from the document",
          "instillFormat": "semi-structured/object",
          "instillUIOrder": 1,
          "required": [],
          "title": "Meta",
          "type": "object"
        },
        "msecs": {
          "description": "Time taken to convert the document",
          "instillFormat": "number",
          "instillUIOrder": 2,
          "title": "MSecs",
          "type": "number"
        }
      },
      "required": [
        "body",
        "meta",
        "msecs",
        "error"
      ],
      "title": "Output",
      "type": "object"
    }
  },
  "TASK_SPLIT_BY_TOKEN": {
    "instillShortDescription": "Split text by token.",
    "input": {
      "description": "Input",
      "instillEditOnNodeFields": [
        "text",
        "model"
      ],
      "instillUIOrder": 0,
      "properties": {
        "chunk_token_size": {
          "default": 500,
          "description": "Number of tokens per text chunk",
          "instillAcceptFormats": [
            "integer"
          ],
          "instillUIOrder": 2,
          "instillUpstreamTypes": [
            "value",
            "reference"
          ],
          "minimum": 1,
          "title": "Chunk Token Size",
          "type": "integer"
        },
        "model": {
          "description": "ID of the model to use for tokenization",
          "enum": [
            "gpt-4",
            "gpt-3.5-turbo",
            "text-davinci-003",
            "text-davinci-002",
            "text-davinci-001",
            "text-curie-001",
            "text-babbage-001",
            "text-ada-001",
            "davinci",
            "curie",
            "babbage",
            "ada",
            "code-davinci-002",
            "code-davinci-001",
            "code-cushman-002",
            "code-cushman-001",
            "davinci-codex",
            "cushman-codex",
            "text-davinci-edit-001",
            "code-davinci-edit-001",
            "text-embedding-ada-002",
            "text-similarity-davinci-001",
            "text-similarity-curie-001",
            "text-similarity-babbage-001",
            "text-similarity-ada-001",
            "text-search-davinci-doc-001",
            "text-search-curie-doc-001",
            "text-search-babbage-doc-001",
            "text-search-ada-doc-001",
            "code-search-babbage-code-001",
            "code-search-ada-code-001",
            "gpt2"
          ],
          "instillAcceptFormats": [
            "string"
          ],
          "instillUIOrder": 1,
          "instillUpstreamTypes": [
            "value",
            "reference",
            "template"
          ],
          "title": "Model",
          "type": "string"
        },
        "text": {
          "description": "Text to be split",
          "instillAcceptFormats": [
            "string"
          ],
          "instillUIMultiline": true,
          "instillUIOrder": 0,
          "instillUpstreamTypes": [
            "value",
            "reference",
            "template"
          ],
          "title": "Text",
          "type": "string"
        }
      },
      "required": [
        "text",
        "model"
      ],
      "title": "Input",
      "type": "object"
    },
    "output": {
      "description": "Output",
      "instillEditOnNodeFields": [
        "texts"
      ],
      "instillUIOrder": 0,
      "properties": {
        "chunk_num": {
          "description": "Total number of output text chunks",
          "instillUIOrder": 2,
          "instillFormat": "integer",
          "title": "Number of Text Chunks",
          "type": "integer"
        },
        "text_chunks": {
          "description": "Text chunks after splitting",
          "instillUIOrder": 1,
          "instillFormat": "array:string",
          "items": {
            "title": "Text Chunk",
            "description": "Text chunk after splitting",
            "instillFormat": "string",
            "instillUIMultiline": true,
            "type": "string"
          },
          "title": "Text Chunks",
          "type": "array"
        },
        "token_count": {
          "description": "Total count of tokens in the input text",
          "instillUIOrder": 0,
          "instillFormat": "integer",
          "title": "Token Count",
          "type": "integer"
        }
      },
      "required": [
        "token_count",
        "text_chunks",
        "chunk_num"
      ],
      "title": "Output",
      "type": "object"
    }
  },
  "TASK_CHUNK_TEXT": {
    "instillShortDescription": "Chunk text with different strategies.",
    "input": {
      "description": "Input",
      "instillEditOnNodeFields": [
        "text",
        "strategy"
      ],
      "instillUIOrder": 0,
      "properties": {
        "text": {
          "$ref": "#/$defs/text"
        },
        "strategy": {
          "description": "Chunking strategy",
          "instillUIOrder": 1,
          "instillAcceptFormats": [
            "string"
          ],
          "instillUpstreamTypes": [
            "value",
            "reference",
            "template"
          ],
          "enum": [
            "token", 
            "recursive",
            "markdown"
          ],
          "properties": {
            "setting": {
              "description": "Chunk Setting",
              "additionalProperties": true,
              "oneOf": [
                {
                  "properties": {
                    "chunk_size": {
                      "$ref": "#/$defs/chunk_size"
                    },
                    "chunk_overlap": {
                      "$ref": "#/$defs/chunk_overlap"
                    },
                    "model_name": {
                      "$ref": "#/$defs/model_name"
                    },
                    "encoding_name": {
                      "description": "Encoding name to use for tokenization",
                      "enum": [
                        "cl100k_base",
                        "p50k_base",
                        "r50k_base",
                        "p50k_edit"
                      ],
                      "instillAcceptFormats": [
                        "string"
                      ],
                      "instillUIOrder": 3,
                      "instillUpstreamTypes": [
                        "value",
                        "reference",
                        "template"
                      ],
                      "title": "Model",
                      "type": "string"
                    },
                    "allowed_special": {
                      "description": "Allowed special tokens",
                      "instillAcceptFormats": [
                        "array:string"
                      ],
                      "instillUIOrder": 4,
                      "instillUpstreamTypes": [
                        "value",
                        "reference",
                        "template"
                      ],
                      "title": "Allowed Special Tokens",
                      "type": "array:string"
                    },
                    "disallowed_special": {
                      "description": "Disallowed special tokens",
                      "instillAcceptFormats": [
                        "array:string"
                      ],
                      "instillUIOrder": 5,
                      "instillUpstreamTypes": [
                        "value",
                        "reference",
                        "template"
                      ],
                      "title": "Disallowed Special Tokens",
                      "type": "array:string"
                    }
                  },
                  "title": "Split by Token"
                }
              ]
            }
          },
          "title": "Strategy",
          "type": "string"
        }
      },
      "required": [
        "text",
        "strategy"
      ],
      "title": "Input",
      "type": "object"
    },
    "output": {
      "description": "Output",
      "instillEditOnNodeFields": [
        "texts"
      ],
      "instillUIOrder": 0,
      "properties": {
        "chunk_num": {
          "description": "Total number of output text chunks",
          "instillUIOrder": 2,
          "instillFormat": "integer",
          "title": "Number of Text Chunks",
          "type": "integer"
        },
        "text_chunks": {
          "description": "Text chunks after splitting",
          "instillUIOrder": 1,
          "instillFormat": "array:string",
          "items": {
            "title": "Text Chunk",
            "description": "Text chunk after splitting",
            "instillFormat": "string",
            "instillUIMultiline": true,
            "type": "string"
          },
          "title": "Text Chunks",
          "type": "array"
        },
        "token_count": {
          "description": "Total count of tokens in the input text",
          "instillUIOrder": 0,
          "instillFormat": "integer",
          "title": "Token Count",
          "type": "integer"
        }
      },
      "required": [
        "token_count",
        "text_chunks",
        "chunk_num"
      ],
      "title": "Output",
      "type": "object"
    }
  }
}
