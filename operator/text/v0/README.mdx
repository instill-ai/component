---
title: "Text"
lang: "en-US"
draft: false
description: "Learn about how to set up a VDP Text component https://github.com/instill-ai/instill-core"
---

The Text component is an operator component that allows users to extract and manipulate text from different sources.
It can carry out the following tasks:

- [Chunk Text](#chunk-text)



## Release Stage

`Alpha`



## Configuration

The component configuration is defined and maintained [here](https://github.com/instill-ai/component/blob/main/operator/text/v0/config/definition.json).







## Supported Tasks

### Chunk Text

Chunk text with different strategies


| Input | ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Task ID (required) | `task` | string | `TASK_CHUNK_TEXT` |
| Text (required) | `text` | string | Text to be chunked |
| Strategy (required) | `strategy` | object | Chunking strategy |






#### Strategy

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| Chunk Setting | setting | object | Chunk Setting  |








#### setting option: 0

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| Allowed Special Tokens   | allowed-special | array |  A list of special tokens that are allowed within chunks.    |
|  chunk-method   | chunk-method | string |  please intput  "Token"   |
| Chunk Overlap   | chunk-overlap | integer |  Determines the number of tokens that overlap between consecutive chunks    |
| Chunk Size   | chunk-size | integer |  Specifies the maximum size of each chunk in terms of the number of tokens    |
| Disallowed Special Tokens   | disallowed-special | array |  A list of special tokens that should not appear within chunks.    |
| Model   | model-name | string |  The name of the model used for tokenization.    there are options: <br/>- gpt-4<br/>- gpt-3.5-turbo<br/>- text-davinci-003<br/>- text-davinci-002<br/>- text-davinci-001<br/>- text-curie-001<br/>- text-babbage-001<br/>- text-ada-001<br/>- davinci<br/>- curie<br/>- babbage<br/>- ada<br/>- code-davinci-002<br/>- code-davinci-001<br/>- code-cushman-002<br/>- code-cushman-001<br/>- davinci-codex<br/>- cushman-codex<br/>- text-davinci-edit-001<br/>- code-davinci-edit-001<br/>- text-embedding-ada-002<br/>- text-similarity-davinci-001<br/>- text-similarity-curie-001<br/>- text-similarity-babbage-001<br/>- text-similarity-ada-001<br/>- text-search-davinci-doc-001<br/>- text-search-curie-doc-001<br/>- text-search-babbage-doc-001<br/>- text-search-ada-doc-001<br/>- code-search-babbage-code-001<br/>- code-search-ada-code-001<br/>- gpt2   |


#### setting option: 1

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
|  chunk-method   | chunk-method | string |  please intput  "Recursive"   |
| Chunk Overlap   | chunk-overlap | integer |  Determines the number of tokens that overlap between consecutive chunks    |
| Chunk Size   | chunk-size | integer |  Specifies the maximum size of each chunk in terms of the number of tokens    |
| Keep Separator   | keep-separator | boolean |  A flag indicating whether to keep the separator characters at the beginning or end of chunks    |
| Model   | model-name | string |  The name of the model used for tokenization.    there are options: <br/>- gpt-4<br/>- gpt-3.5-turbo<br/>- text-davinci-003<br/>- text-davinci-002<br/>- text-davinci-001<br/>- text-curie-001<br/>- text-babbage-001<br/>- text-ada-001<br/>- davinci<br/>- curie<br/>- babbage<br/>- ada<br/>- code-davinci-002<br/>- code-davinci-001<br/>- code-cushman-002<br/>- code-cushman-001<br/>- davinci-codex<br/>- cushman-codex<br/>- text-davinci-edit-001<br/>- code-davinci-edit-001<br/>- text-embedding-ada-002<br/>- text-similarity-davinci-001<br/>- text-similarity-curie-001<br/>- text-similarity-babbage-001<br/>- text-similarity-ada-001<br/>- text-search-davinci-doc-001<br/>- text-search-curie-doc-001<br/>- text-search-babbage-doc-001<br/>- text-search-ada-doc-001<br/>- code-search-babbage-code-001<br/>- code-search-ada-code-001<br/>- gpt2   |
| Separators   | separators | array |  A list of strings representing the separators used to split the text.    |


#### setting option: 2

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
|  chunk-method   | chunk-method | string |  please intput  "Markdown"   |
| Chunk Overlap   | chunk-overlap | integer |  Determines the number of tokens that overlap between consecutive chunks    |
| Chunk Size   | chunk-size | integer |  Specifies the maximum size of each chunk in terms of the number of tokens    |
| Code Blocks   | code-blocks | boolean |  A flag indicating whether code blocks should be treated as a single unit    |
| Model   | model-name | string |  The name of the model used for tokenization.    there are options: <br/>- gpt-4<br/>- gpt-3.5-turbo<br/>- text-davinci-003<br/>- text-davinci-002<br/>- text-davinci-001<br/>- text-curie-001<br/>- text-babbage-001<br/>- text-ada-001<br/>- davinci<br/>- curie<br/>- babbage<br/>- ada<br/>- code-davinci-002<br/>- code-davinci-001<br/>- code-cushman-002<br/>- code-cushman-001<br/>- davinci-codex<br/>- cushman-codex<br/>- text-davinci-edit-001<br/>- code-davinci-edit-001<br/>- text-embedding-ada-002<br/>- text-similarity-davinci-001<br/>- text-similarity-curie-001<br/>- text-similarity-babbage-001<br/>- text-similarity-ada-001<br/>- text-search-davinci-doc-001<br/>- text-search-curie-doc-001<br/>- text-search-babbage-doc-001<br/>- text-search-ada-doc-001<br/>- code-search-babbage-code-001<br/>- code-search-ada-code-001<br/>- gpt2   |





| Output | ID | Type | Description |
| :--- | :--- | :--- | :--- |
| Token Count | `token-count` | integer | Total count of tokens in the original input text |
| Text Chunks | `text-chunks` | array[object] | Text chunks after splitting |
| Number of Text Chunks | `chunk-num` | integer | Total number of output text chunks |
| Token Count Chunks | `chunks-token-count` | integer | Total count of tokens in the output text chunks |







#### Text Chunks

| Field | Field ID | Type | Note |
| :--- | :--- | :--- | :--- |
| End Position | end-position | integer | The ending position of the chunk in the original text |
| Start Position | start-position | integer | The starting position of the chunk in the original text |
| Text | text | string | Text chunk after splitting |
| Token Count | token-count | integer | Count of tokens in a chunk |







